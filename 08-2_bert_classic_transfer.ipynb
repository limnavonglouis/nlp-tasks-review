{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"08-2_bert_classic_transfer.ipynb","version":"0.3.2","provenance":[{"file_id":"1YlWZJootbsLAAHtuGW7tSlz-1lduSm70","timestamp":1561714911441},{"file_id":"10bEbJLtnQF1w2mizZKE_IiIr8DfgjbD8","timestamp":1561656942077},{"file_id":"1wLMJ3Z6e5tPS5oqerjk7HzANLMPRGCGP","timestamp":1561587317659},{"file_id":"1EGtdRkg92gQiCp9rMOz-3vyY_AxeMF1H","timestamp":1561583247231},{"file_id":"1XBk0FvmNhYMCxKkS4rgv--dThkc3w1E_","timestamp":1561415310622},{"file_id":"1z67oFDLWiSfpU5FMAjjFF6bcwA1sKdMX","timestamp":1561301600847}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ONguLGXuLm4q","colab_type":"text"},"source":["**Simple** model\n","Based on deep learning course\n","\n","with use transfer learning"]},{"cell_type":"code","metadata":{"id":"d-YHQZdEjAb2","colab_type":"code","outputId":"02183607-1eb0-4283-eeed-f3a2d0cb154b","executionInfo":{"status":"ok","timestamp":1561721029066,"user_tz":-120,"elapsed":15945,"user":{"displayName":"Louis Limnavong","photoUrl":"https://lh6.googleusercontent.com/-0meW06tHROg/AAAAAAAAAAI/AAAAAAAAACk/6yo6r_PsYc4/s64/photo.jpg","userId":"01214566586610519367"}},"colab":{"base_uri":"https://localhost:8080/","height":490}},"source":["! pip install pytorch-pretrained-bert"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting pytorch-pretrained-bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\r\u001b[K     |██▋                             | 10kB 17.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 4.9MB/s \n","\u001b[?25hCollecting regex (from pytorch-pretrained-bert)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)\n","\u001b[K     |████████████████████████████████| 655kB 57.6MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.9.167)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.16.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.3.9)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n","Requirement already satisfied: botocore<1.13.0,>=1.12.167 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.12.167)\n","Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.167->boto3->pytorch-pretrained-bert) (0.14)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.167->boto3->pytorch-pretrained-bert) (2.5.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.167->boto3->pytorch-pretrained-bert) (1.12.0)\n","Building wheels for collected packages: regex\n","  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/35/e4/80/abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473\n","Successfully built regex\n","Installing collected packages: regex, pytorch-pretrained-bert\n","Successfully installed pytorch-pretrained-bert-0.6.2 regex-2019.6.8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7raJ3n6Ujww9","colab_type":"code","outputId":"71d6f589-4468-46ca-f4c3-95d21e630e57","executionInfo":{"status":"ok","timestamp":1561721224150,"user_tz":-120,"elapsed":146617,"user":{"displayName":"Louis Limnavong","photoUrl":"https://lh6.googleusercontent.com/-0meW06tHROg/AAAAAAAAAAI/AAAAAAAAACk/6yo6r_PsYc4/s64/photo.jpg","userId":"01214566586610519367"}},"colab":{"base_uri":"https://localhost:8080/","height":154}},"source":["# for colab \n","\n","# 0. imports \n","\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# 1. Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# 2. Mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |▎                               | 10kB 24.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 5.7MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 5.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 5.0MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 5.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 5.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 5.0MB/s \n","\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_YKqPnZko4gC","colab_type":"code","outputId":"9d7e8d7a-8f0d-4610-80dc-120950b21c8d","executionInfo":{"status":"ok","timestamp":1561721229601,"user_tz":-120,"elapsed":2079,"user":{"displayName":"Louis Limnavong","photoUrl":"https://lh6.googleusercontent.com/-0meW06tHROg/AAAAAAAAAAI/AAAAAAAAACk/6yo6r_PsYc4/s64/photo.jpg","userId":"01214566586610519367"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["% cd /content/drive/'My Drive'/master_thesis\n","% ls "],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/master_thesis\n","bert_model_test.pth  convert_examples_to_features.py  \u001b[0m\u001b[01;34moutputs\u001b[0m/      \u001b[01;34mreports\u001b[0m/\n","\u001b[01;34mcache\u001b[0m/               \u001b[01;34mdata\u001b[0m/                            \u001b[01;34m__pycache__\u001b[0m/  tools.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HRlnVHrDjL__","colab_type":"code","outputId":"484b426f-99ec-410f-e037-167c01e25353","executionInfo":{"status":"ok","timestamp":1561730257886,"user_tz":-120,"elapsed":877,"user":{"displayName":"Louis Limnavong","photoUrl":"https://lh6.googleusercontent.com/-0meW06tHROg/AAAAAAAAAAI/AAAAAAAAACk/6yo6r_PsYc4/s64/photo.jpg","userId":"01214566586610519367"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["import torch\n","from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification\n","\n","# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n","import logging\n","logging.basicConfig(level=logging.INFO)\n","\n","# Load pre-trained model tokenizer (vocabulary)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"OyrbKnRfpT8m","colab_type":"code","colab":{}},"source":["import pandas as pd \n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xIrmvKVWjpmc","colab_type":"code","colab":{}},"source":["from __future__ import print_function, division\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from random import randrange\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6PP3zKgxkqbM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":339},"outputId":"cdcc44fa-c6d9-4bca-ff4b-06ee9a7010e7","executionInfo":{"status":"ok","timestamp":1561730274980,"user_tz":-120,"elapsed":10219,"user":{"displayName":"Louis Limnavong","photoUrl":"https://lh6.googleusercontent.com/-0meW06tHROg/AAAAAAAAAAI/AAAAAAAAACk/6yo6r_PsYc4/s64/photo.jpg","userId":"01214566586610519367"}}},"source":["from pytorch_pretrained_bert import BertConfig\n","\n","config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n","        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n","\n","num_labels = 2\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","INFO:pytorch_pretrained_bert.modeling:extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpfgyrapxj\n","INFO:pytorch_pretrained_bert.modeling:Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","INFO:pytorch_pretrained_bert.modeling:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","INFO:pytorch_pretrained_bert.modeling:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ekkoPInGkszE","colab_type":"code","colab":{}},"source":["#dat = pd.read_csv('data/final_full.csv')\n","dat = pd.read_csv('data/final_sub.csv')\n","dat.head()\n","\n","X = dat['reviewText']\n","y = dat['label']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aQ3fFY9XQz63","colab_type":"code","colab":{}},"source":["X_train = X_train.values.tolist()\n","X_test = X_test.values.tolist()\n","\n","y_train = pd.get_dummies(y_train).values.tolist()\n","y_test = pd.get_dummies(y_test).values.tolist()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0pCqP1Qdp2Iz","colab_type":"code","colab":{}},"source":["max_seq_length = 256\n","# to check \n","\n","class text_dataset(Dataset):\n","    def __init__(self,x_y_list, transform=None):\n","        \n","        self.x_y_list = x_y_list\n","        self.transform = transform\n","        \n","    def __getitem__(self,index):\n","        \n","        tokenized_review = tokenizer.tokenize(self.x_y_list[0][index])\n","        \n","        if len(tokenized_review) > max_seq_length:\n","            tokenized_review = tokenized_review[:max_seq_length]\n","            \n","        ids_review  = tokenizer.convert_tokens_to_ids(tokenized_review)\n","\n","        padding = [0] * (max_seq_length - len(ids_review))\n","        \n","        ids_review += padding\n","        \n","        assert len(ids_review) == max_seq_length\n","        \n","        #print(ids_review)\n","        ids_review = torch.tensor(ids_review)\n","        \n","        sentiment = self.x_y_list[1][index] # color        \n","        list_of_labels = [torch.from_numpy(np.array(sentiment))]\n","        \n","        \n","        return ids_review, list_of_labels[0]\n","    \n","    def __len__(self):\n","        return len(self.x_y_list[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KbeW9HB5p685","colab_type":"code","outputId":"8df1a369-97d8-460e-e80f-05e988a12457","executionInfo":{"status":"ok","timestamp":1561721322022,"user_tz":-120,"elapsed":610,"user":{"displayName":"Louis Limnavong","photoUrl":"https://lh6.googleusercontent.com/-0meW06tHROg/AAAAAAAAAAI/AAAAAAAAACk/6yo6r_PsYc4/s64/photo.jpg","userId":"01214566586610519367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["batch_size = 16\n","\n","train_lists = [X_train, y_train]\n","test_lists = [X_test, y_test]\n","\n","training_dataset = text_dataset(x_y_list = train_lists )\n","\n","test_dataset = text_dataset(x_y_list = test_lists )\n","\n","dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=0),\n","                   'val':torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n","                   }\n","dataset_sizes = {'train':len(train_lists[0]),\n","                'val':len(test_lists[0])}\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sL6BUFhdp9aU","colab_type":"code","colab":{}},"source":["def train_model(model, loss_fn, optimizer, num_epochs=25):\n","    since = time.time()\n","    print('starting')\n","    \n","    phase = 'train'\n","    model.train()\n","    \n","    loss_train = np.zeros(num_epochs)\n","    acc_train = np.zeros(num_epochs)\n","    \n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","\n","        for inputs, labels in dataloaders_dict[phase]:\n","          \n","            inputs = inputs.to(device) \n","            labels = labels.to(device)\n","            optimizer.zero_grad()\n","            \n","            with torch.set_grad_enabled(phase == 'train'):\n","              \n","              \n","              outputs = model(inputs)\n","              outputs = F.softmax(outputs,dim=1)\n","              loss = loss_fn(outputs, torch.max(labels.float(), 1)[1])\n","\n","              loss.backward()\n","              optimizer.step()\n","            \n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(torch.max(outputs, 1)[1] == torch.max(labels, 1)[1])\n","           \n","\n","        epoch_loss = running_loss / dataset_sizes[phase]\n","        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","        loss_train[epoch] = epoch_loss\n","        acc_train[epoch] = epoch_acc\n","        \n","        print('Train - Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n","        \n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    \n","    return loss_train, acc_train"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x7-U__uEqlgQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"25a5697c-2b60-4fce-e61d-69e86f1e336b","executionInfo":{"status":"ok","timestamp":1561730300144,"user_tz":-120,"elapsed":575,"user":{"displayName":"Louis Limnavong","photoUrl":"https://lh6.googleusercontent.com/-0meW06tHROg/AAAAAAAAAAI/AAAAAAAAACk/6yo6r_PsYc4/s64/photo.jpg","userId":"01214566586610519367"}}},"source":["#model.to(device)\n","\n","for param in model.bert.parameters():\n","            param.requires_grad = True\n","    \n","#model.classifier.weight.requires_grad = True\n","\n","model"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): BertLayerNorm()\n","      (dropout): Dropout(p=0.1)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"C5tKQOHGr__b","colab_type":"code","colab":{}},"source":["lrlast = .001\n","lrmain = .00001\n","#optim1 = optim.Adam(\n","#    [\n","#        {\"params\":model.bert.parameters(),\"lr\": lrmain},\n","#        {\"params\":model.classifier.parameters(), \"lr\": lrlast},\n","#       \n","#   ])\n","\n","\n","optim1 = optim.Adam(model.parameters(), lr=lrmain)\n","optimizer_ft = optim1\n","criterion = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbeYSsOdsEaT","colab_type":"code","outputId":"9291b991-60af-4842-9e13-3fa1f7178657","executionInfo":{"status":"ok","timestamp":1561724965961,"user_tz":-120,"elapsed":1307264,"user":{"displayName":"Louis Limnavong","photoUrl":"https://lh6.googleusercontent.com/-0meW06tHROg/AAAAAAAAAAI/AAAAAAAAACk/6yo6r_PsYc4/s64/photo.jpg","userId":"01214566586610519367"}},"colab":{"base_uri":"https://localhost:8080/","height":302}},"source":["model_ft1 = train_model(model, criterion, optimizer_ft, num_epochs=5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["starting\n","Epoch 0/4\n","----------\n","Train - Loss: 0.4801 Acc: 0.8162\n","Epoch 1/4\n","----------\n","Train - Loss: 0.3557 Acc: 0.9580\n","Epoch 2/4\n","----------\n","Train - Loss: 0.3415 Acc: 0.9711\n","Epoch 3/4\n","----------\n","Train - Loss: 0.3390 Acc: 0.9747\n","Epoch 4/4\n","----------\n","Train - Loss: 0.3341 Acc: 0.9789\n","Training complete in 21m 47s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Xej55F6EsruR","colab_type":"code","colab":{}},"source":["def test(model, loss_fn):\n","    \n","    phase = 'val'\n","    model.eval()\n","\n","    running_corrects = 0.0\n","    running_loss = 0.0\n","    \n","\n","    for inputs, labels in dataloaders_dict[phase]:\n","\n","      inputs = inputs.to(device) \n","      labels = labels.to(device)\n","\n","\n","\n","      outputs = model(inputs)\n","      loss = loss_fn(outputs, torch.max(labels.float(), 1)[1])\n","\n","\n","      # statistics\n","      running_loss += loss.item() * inputs.size(0)\n","      running_corrects += torch.sum(torch.max(outputs, 1)[1] == torch.max(labels, 1)[1])\n","   \n","    val_loss = running_loss / dataset_sizes[phase]\n","    val_acc = running_corrects.double() / dataset_sizes[phase]  \n","\n","    print('Test - Loss: {:.4f} Acc: {:.4f}'.format(val_loss, val_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8a2Ifxr-Z3tD","colab_type":"code","outputId":"dbaa3a5c-f20e-4187-ff9e-14dacfbb58b3","executionInfo":{"status":"ok","timestamp":1561725005221,"user_tz":-120,"elapsed":10807,"user":{"displayName":"Louis Limnavong","photoUrl":"https://lh6.googleusercontent.com/-0meW06tHROg/AAAAAAAAAAI/AAAAAAAAACk/6yo6r_PsYc4/s64/photo.jpg","userId":"01214566586610519367"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test(model, criterion)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test - Loss: 0.2757 Acc: 0.9500\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0lq8xQuzac09","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}